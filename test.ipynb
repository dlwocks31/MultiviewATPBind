{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets import ATPBind3D\n",
    "\n",
    "# dataset_orig = ATPBind3D()\n",
    "# dataset_orig.initialize_mask_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Undersampling: all ones\n",
      "Initialize Weighting: all ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ATPBind3D(\n",
       "  #sample: 631\n",
       "  #task: 1\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ATPBind3D(to_slice=True)\n",
    "dataset.initialize_mask_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from torchdrug import utils, data\n",
    "import os\n",
    "import torch\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "from lib.utils import generate_mean_ensemble_metrics_auto, read_initial_csv, aggregate_pred_dataframe\n",
    "GPU = 0\n",
    "\n",
    "from atpbind_main import main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 8\n",
      "init pipeline, model: esm-t33, dataset: atpbind3d, gpus: [0]\n",
      "load model esm-t33, kwargs: {'gpu': 0, 'freeze_esm': False, 'freeze_layer_count': 30}\n",
      "get dataset atpbind3d\n",
      "Initialize Undersampling: all ones\n",
      "Initialize Weighting: all ones\n",
      "train samples: 302, valid samples: 76, test samples: 41\n",
      "use cyclic lr scheduler\n",
      "pipeline batch_size: 8\n",
      "0m20s {'sensitivity': 0.5949, 'precision': 0.5902, 'mcc': 0.5702, 'micro_auprc': 0.6137, 'valid_mcc': 0.541, 'train_bce': 0.166, 'valid_bce': 0.1067, 'lr': 0.00084}\n",
      "0m19s {'sensitivity': 0.6938, 'precision': 0.6601, 'mcc': 0.6586, 'micro_auprc': 0.7047, 'valid_mcc': 0.6246, 'train_bce': 0.0828, 'valid_bce': 0.0937, 'lr': 0.00138}\n",
      "0m20s {'sensitivity': 0.6204, 'precision': 0.6946, 'mcc': 0.6389, 'micro_auprc': 0.6339, 'valid_mcc': 0.6264, 'train_bce': 0.0429, 'valid_bce': 0.1536, 'lr': 0.00192}\n",
      "0m21s {'sensitivity': 0.6715, 'precision': 0.6651, 'mcc': 0.6501, 'micro_auprc': 0.6658, 'valid_mcc': 0.6298, 'train_bce': 0.0323, 'valid_bce': 0.1245, 'lr': 0.00246}\n",
      "0m23s {'sensitivity': 0.6061, 'precision': 0.7252, 'mcc': 0.6463, 'micro_auprc': 0.6758, 'valid_mcc': 0.6307, 'train_bce': 0.0324, 'valid_bce': 0.1436, 'lr': 0.003}\n",
      "0m26s {'sensitivity': 0.6236, 'precision': 0.7122, 'mcc': 0.6495, 'micro_auprc': 0.6693, 'valid_mcc': 0.6348, 'train_bce': 0.0352, 'valid_bce': 0.1496, 'lr': 0.00246}\n",
      "0m28s {'sensitivity': 0.6427, 'precision': 0.6694, 'mcc': 0.6376, 'micro_auprc': 0.6431, 'valid_mcc': 0.6313, 'train_bce': 0.0261, 'valid_bce': 0.1408, 'lr': 0.00192}\n",
      "0m28s {'sensitivity': 0.5885, 'precision': 0.7425, 'mcc': 0.6449, 'micro_auprc': 0.6504, 'valid_mcc': 0.6517, 'train_bce': 0.0122, 'valid_bce': 0.1333, 'lr': 0.00138}\n",
      "0m27s {'sensitivity': 0.6061, 'precision': 0.7692, 'mcc': 0.6677, 'micro_auprc': 0.6671, 'valid_mcc': 0.6596, 'train_bce': 0.0065, 'valid_bce': 0.1664, 'lr': 0.00084}\n",
      "0m29s {'sensitivity': 0.5821, 'precision': 0.77, 'mcc': 0.6543, 'micro_auprc': 0.6674, 'valid_mcc': 0.6661, 'train_bce': 0.0025, 'valid_bce': 0.1849, 'lr': 0.0003}\n",
      "single_run done. Last MCC: 0.6543\n"
     ]
    }
   ],
   "source": [
    "main(model_key='esm-t33', valid_fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init pipeline, model: lm-gearnet, dataset: atpbind3d, gpus: [1]\n",
      "load model lm-gearnet, kwargs: {'gpu': 1, 'lm_type': 'esm-t33', 'gearnet_hidden_dim_size': 512, 'gearnet_hidden_dim_count': 4, 'lm_freeze_layer_count': 30}\n",
      "freeze_lm: 30\n",
      "get dataset atpbind3d\n",
      "Initialize Undersampling: all ones\n",
      "Initialize Weighting: all ones\n",
      "train samples: 332, valid samples: 84, test samples: 41\n",
      "use cyclic lr scheduler\n",
      "pipeline batch_size: 8\n"
     ]
    }
   ],
   "source": [
    "from lib.pipeline import Pipeline\n",
    "from torchdrug import utils, data\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "CYCLE_SIZE = 10\n",
    "pipeline = Pipeline(\n",
    "    dataset='atpbind3d',\n",
    "    model='lm-gearnet',\n",
    "    gpus=[1],\n",
    "    model_kwargs={\n",
    "        'gpu': 1,\n",
    "        'lm_type': 'esm-t33',\n",
    "        'gearnet_hidden_dim_size': 512,\n",
    "        'gearnet_hidden_dim_count': 4,\n",
    "        'lm_freeze_layer_count': 30,\n",
    "    },\n",
    "    scheduler='cyclic',\n",
    "    scheduler_kwargs={\n",
    "        'base_lr': 3e-4,\n",
    "        'max_lr': 3e-3,\n",
    "        'step_size_up': CYCLE_SIZE / 2,\n",
    "        'step_size_down': CYCLE_SIZE / 2,\n",
    "        'cycle_momentum': False\n",
    "    },\n",
    "    batch_size=8,\n",
    "    dataset_args={\n",
    "        'to_slice': True,\n",
    "        'max_slice_length': 650,\n",
    "        'padding': 50,\n",
    "    },\n",
    "    valid_fold_num=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m1s {'sensitivity': 0.5074, 'precision': 0.4252, 'mcc': 0.4363, 'micro_auprc': 0.4531, 'valid_mcc': 0.4378, 'train_bce': 0.1691, 'valid_bce': 0.1483, 'lr': 0.00084}\n",
      "0m59s {'sensitivity': 0.5923, 'precision': 0.5958, 'mcc': 0.5745, 'micro_auprc': 0.5905, 'valid_mcc': 0.5859, 'train_bce': 0.0745, 'valid_bce': 0.1103, 'lr': 0.00138}\n",
      "0m58s {'sensitivity': 0.6071, 'precision': 0.6559, 'mcc': 0.614, 'micro_auprc': 0.6314, 'valid_mcc': 0.6012, 'train_bce': 0.0469, 'valid_bce': 0.1081, 'lr': 0.00192}\n",
      "0m59s {'sensitivity': 0.5565, 'precision': 0.6788, 'mcc': 0.598, 'micro_auprc': 0.5873, 'valid_mcc': 0.6143, 'train_bce': 0.0321, 'valid_bce': 0.1387, 'lr': 0.00246}\n",
      "1m0s {'sensitivity': 0.6161, 'precision': 0.5061, 'mcc': 0.5349, 'micro_auprc': 0.5965, 'valid_mcc': 0.6186, 'train_bce': 0.0313, 'valid_bce': 0.1092, 'lr': 0.003}\n",
      "1m1s {'sensitivity': 0.4301, 'precision': 0.7918, 'mcc': 0.5699, 'micro_auprc': 0.6209, 'valid_mcc': 0.6265, 'train_bce': 0.023, 'valid_bce': 0.1262, 'lr': 0.00246}\n",
      "1m2s {'sensitivity': 0.619, 'precision': 0.7247, 'mcc': 0.6552, 'micro_auprc': 0.6682, 'valid_mcc': 0.6722, 'train_bce': 0.0126, 'valid_bce': 0.1235, 'lr': 0.00192}\n",
      "1m3s {'sensitivity': 0.6086, 'precision': 0.7125, 'mcc': 0.6435, 'micro_auprc': 0.6593, 'valid_mcc': 0.6774, 'train_bce': 0.0069, 'valid_bce': 0.1203, 'lr': 0.00138}\n",
      "1m3s {'sensitivity': 0.6042, 'precision': 0.7675, 'mcc': 0.6676, 'micro_auprc': 0.6616, 'valid_mcc': 0.6691, 'train_bce': 0.002, 'valid_bce': 0.1623, 'lr': 0.00084}\n",
      "1m5s {'sensitivity': 0.622, 'precision': 0.7398, 'mcc': 0.6643, 'micro_auprc': 0.6665, 'valid_mcc': 0.6772, 'train_bce': 0.0007, 'valid_bce': 0.171, 'lr': 0.0003}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sensitivity': 0.5074,\n",
       "  'precision': 0.4252,\n",
       "  'mcc': 0.4363,\n",
       "  'micro_auprc': 0.4531,\n",
       "  'valid_mcc': 0.4378,\n",
       "  'train_bce': 0.1691,\n",
       "  'valid_bce': 0.1483,\n",
       "  'lr': 0.00084},\n",
       " {'sensitivity': 0.5923,\n",
       "  'precision': 0.5958,\n",
       "  'mcc': 0.5745,\n",
       "  'micro_auprc': 0.5905,\n",
       "  'valid_mcc': 0.5859,\n",
       "  'train_bce': 0.0745,\n",
       "  'valid_bce': 0.1103,\n",
       "  'lr': 0.00138},\n",
       " {'sensitivity': 0.6071,\n",
       "  'precision': 0.6559,\n",
       "  'mcc': 0.614,\n",
       "  'micro_auprc': 0.6314,\n",
       "  'valid_mcc': 0.6012,\n",
       "  'train_bce': 0.0469,\n",
       "  'valid_bce': 0.1081,\n",
       "  'lr': 0.00192},\n",
       " {'sensitivity': 0.5565,\n",
       "  'precision': 0.6788,\n",
       "  'mcc': 0.598,\n",
       "  'micro_auprc': 0.5873,\n",
       "  'valid_mcc': 0.6143,\n",
       "  'train_bce': 0.0321,\n",
       "  'valid_bce': 0.1387,\n",
       "  'lr': 0.00246},\n",
       " {'sensitivity': 0.6161,\n",
       "  'precision': 0.5061,\n",
       "  'mcc': 0.5349,\n",
       "  'micro_auprc': 0.5965,\n",
       "  'valid_mcc': 0.6186,\n",
       "  'train_bce': 0.0313,\n",
       "  'valid_bce': 0.1092,\n",
       "  'lr': 0.003},\n",
       " {'sensitivity': 0.4301,\n",
       "  'precision': 0.7918,\n",
       "  'mcc': 0.5699,\n",
       "  'micro_auprc': 0.6209,\n",
       "  'valid_mcc': 0.6265,\n",
       "  'train_bce': 0.023,\n",
       "  'valid_bce': 0.1262,\n",
       "  'lr': 0.00246},\n",
       " {'sensitivity': 0.619,\n",
       "  'precision': 0.7247,\n",
       "  'mcc': 0.6552,\n",
       "  'micro_auprc': 0.6682,\n",
       "  'valid_mcc': 0.6722,\n",
       "  'train_bce': 0.0126,\n",
       "  'valid_bce': 0.1235,\n",
       "  'lr': 0.00192},\n",
       " {'sensitivity': 0.6086,\n",
       "  'precision': 0.7125,\n",
       "  'mcc': 0.6435,\n",
       "  'micro_auprc': 0.6593,\n",
       "  'valid_mcc': 0.6774,\n",
       "  'train_bce': 0.0069,\n",
       "  'valid_bce': 0.1203,\n",
       "  'lr': 0.00138},\n",
       " {'sensitivity': 0.6042,\n",
       "  'precision': 0.7675,\n",
       "  'mcc': 0.6676,\n",
       "  'micro_auprc': 0.6616,\n",
       "  'valid_mcc': 0.6691,\n",
       "  'train_bce': 0.002,\n",
       "  'valid_bce': 0.1623,\n",
       "  'lr': 0.00084},\n",
       " {'sensitivity': 0.622,\n",
       "  'precision': 0.7398,\n",
       "  'mcc': 0.6643,\n",
       "  'micro_auprc': 0.6665,\n",
       "  'valid_mcc': 0.6772,\n",
       "  'train_bce': 0.0007,\n",
       "  'valid_bce': 0.171,\n",
       "  'lr': 0.0003}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.train_until_fit(patience=10, max_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_slices, protein_to_slices\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_tensor_to_num, round_dict\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241m.\u001b[39mdataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchdrug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      7\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mProteinView(view\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from lib.datasets import get_slices, protein_to_slices\n",
    "from lib.utils import dict_tensor_to_num, round_dict\n",
    "\n",
    "dataset = pipeline.dataset\n",
    "\n",
    "from torchdrug import transforms\n",
    "pipeline.dataset.transform = transforms.ProteinView(view='residue')\n",
    "\n",
    "train_set, valid_set, test_set = pipeline.dataset.split()\n",
    "\n",
    "def infer_sliced(pipeline, protein, max_slice_length=550, padding=100):\n",
    "    GPU = 1\n",
    "    target = protein.target\n",
    "    intermediate_preds = []\n",
    "    sliced_proteins, _ = protein_to_slices(protein, target, max_slice_length=max_slice_length, padding=padding)\n",
    "    dataloader = data.DataLoader(sliced_proteins, batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = utils.cuda(batch, device=torch.device(f'cuda:{GPU}'))\n",
    "            pred = pipeline.task.predict({\"graph\": batch})\n",
    "            intermediate_preds.append(pred)\n",
    "    final_preds = torch.zeros(target.shape)\n",
    "    for i, (start, end) in enumerate(get_slices(target.shape[0], max_slice_length=max_slice_length, padding=padding)):\n",
    "        final_preds[start:end] += intermediate_preds[i].cpu()\n",
    "        if i > 0:\n",
    "            final_preds[start:start+padding] /= 2\n",
    "    return final_preds\n",
    "\n",
    "\n",
    "\n",
    "def get_pred_and_target(data_set):\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for item in data_set:\n",
    "        pred = infer_sliced(pipeline, item['graph'])\n",
    "        preds.append(pred)\n",
    "\n",
    "        dataloader = data.DataLoader([item], batch_size=1, shuffle=False)    \n",
    "        target = pipeline.task.target(next(iter(dataloader)))\n",
    "        targets.append(target)\n",
    "        \n",
    "    pred = utils.cat(preds)\n",
    "    target = utils.cat(targets)\n",
    "    return pred, target\n",
    "\n",
    "\n",
    "pred, target = get_pred_and_target(test_set)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "metric = pipeline.task.evaluate(pred, target, threshold=0)\n",
    "round_dict(dict_tensor_to_num(metric), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensitivity': 0.6424,\n",
       " 'precision': 0.7193,\n",
       " 'mcc': 0.6654,\n",
       " 'micro_auprc': 0.667}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = pipeline.task.evaluate(pred, target, threshold=-3)\n",
    "round_dict(dict_tensor_to_num(metric), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6646703454160542, 0.662160158839212, 0.6612423519012024, 0.6609006221576132, 0.662631888129046, 0.6633440897293058, 0.6609656771780936, 0.6615542827514305, 0.662292589338338, 0.6646785832673293, 0.6654471338851848, 0.6639765149700037, 0.6629371748530145, 0.6599839387737801, 0.6601611596247207, 0.6628192745832914, 0.6623962673658689, 0.6605035113758178, 0.6619764471630109, 0.6609258404606511, 0.6621974831143543, 0.6616050602318791, 0.6635467778801908, 0.6637966016312562, 0.6633967444009901, 0.6636560757280595, 0.6663065592044322, 0.6655319605896771, 0.6668761294871491, 0.6643781664055507, 0.6656655207514386, 0.6649196576071046, 0.6670010722062665, 0.6645088344438979, 0.6623756303164436, 0.6616430052226454, 0.6616264425799427, 0.6601939905847326, 0.6601939905847326, 0.660909513699043, 0.6616271166235279]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.8, 0.6670010722062665)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_mcc(pipeline, valid_set):\n",
    "    pred, target = get_pred_and_target(valid_set)\n",
    "    thresholds = np.linspace(-4, 0, num=41)\n",
    "    mcc_values = [pipeline.task.evaluate(pred, target, threshold=th)['mcc'] for th in thresholds]\n",
    "    \n",
    "    max_mcc_idx = np.argmax(mcc_values)\n",
    "    print(mcc_values)\n",
    "    return round(thresholds[max_mcc_idx], 2), mcc_values[max_mcc_idx]\n",
    "\n",
    "\n",
    "get_best_mcc(pipeline, valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensitivity': 0.5979,\n",
       " 'precision': 0.7735,\n",
       " 'mcc': 0.667,\n",
       " 'micro_auprc': 0.667}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = pipeline.task.evaluate(pred, target, threshold=-0.8)\n",
    "round_dict(dict_tensor_to_num(metric), 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
